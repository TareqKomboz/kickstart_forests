{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Machine Learning Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/RtmSimulation_kickstart.csv', index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: visualize the data, print summary stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define target and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['lai']\n",
    "X = df.iloc[:,1:13]\n",
    "X_sentinel = df.iloc[:,3:13]\n",
    "X_species_sentinel = df.iloc[:,2:13]\n",
    "X_wetness_sentinel = df.iloc[:,[1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select input data\n",
    "X = X_wetness_sentinel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    wetness  Sentinel_2A_492.4  Sentinel_2A_559.8  Sentinel_2A_664.6  \\\n",
       " id                                                                     \n",
       " 1      0.36           0.062092           0.131702           0.043197   \n",
       " 2      0.47           0.052807           0.129987           0.043061   \n",
       " 3      0.68           0.047937           0.139421           0.045780   \n",
       " 4      0.80           0.045907           0.107761           0.033984   \n",
       " 5      0.48           0.051712           0.136293           0.041502   \n",
       " \n",
       "     Sentinel_2A_704.1  Sentinel_2A_740.5  Sentinel_2A_782.8  \\\n",
       " id                                                            \n",
       " 1            0.177134           0.401750           0.458003   \n",
       " 2            0.153641           0.407523           0.466853   \n",
       " 3            0.157121           0.395428           0.441620   \n",
       " 4            0.128237           0.341315           0.385277   \n",
       " 5            0.167564           0.407460           0.454137   \n",
       " \n",
       "     Sentinel_2A_832.8  Sentinel_2A_864.7  Sentinel_2A_1613.7  \\\n",
       " id                                                             \n",
       " 1            0.463287           0.465697            0.224946   \n",
       " 2            0.477236           0.469157            0.228034   \n",
       " 3            0.448626           0.448503            0.215900   \n",
       " 4            0.382241           0.380013            0.241785   \n",
       " 5            0.464966           0.459594            0.220666   \n",
       " \n",
       "     Sentinel_2A_2202.4  \n",
       " id                      \n",
       " 1             0.094398  \n",
       " 2             0.096956  \n",
       " 3             0.090629  \n",
       " 4             0.105857  \n",
       " 5             0.085389  ,\n",
       " id\n",
       " 1    5.10\n",
       " 2    5.34\n",
       " 3    4.53\n",
       " 4    2.10\n",
       " 5    5.34\n",
       " Name: lai, dtype: float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(), y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y)\n",
    "\n",
    "# val set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, shuffle=True, stratify=y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All features to numerical and Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Identifying categorical and numerical columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "numerical_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Creating a preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='mean'), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "X_val = preprocessor.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp transfromation concat with original data\n",
    "X_train_exp = np.exp(X_train)\n",
    "X_test_exp = np.exp(X_test)\n",
    "X_val_exp = np.exp(X_val)\n",
    "X_train_exp = np.concatenate((X_train, X_train_exp), axis = 1)\n",
    "X_test_exp = np.concatenate((X_test, X_test_exp), axis = 1)\n",
    "X_val_exp = np.concatenate((X_val, X_val_exp), axis = 1)\n",
    "\n",
    "\n",
    "# standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_norm = scaler.transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "X_val_norm = scaler.transform(X_val)\n",
    "\n",
    "# standardization + exp concat\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_exp)\n",
    "X_train_scaled_exp = scaler.transform(X_train_exp)\n",
    "X_test_scaled_exp = scaler.transform(X_test_exp)\n",
    "X_val_scaled_exp = scaler.transform(X_val_exp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select standardized input data\n",
    "X_train = X_train_scaled\n",
    "X_test = X_test_scaled\n",
    "X_val = X_val_scaled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08773349, -0.28812957, -0.46299568, ...,  0.37337968,\n",
       "         0.41746805,  0.20413506],\n",
       "       [-0.36026731,  0.1068488 ,  0.11779769, ...,  0.44589759,\n",
       "        -0.28264652, -0.51328595],\n",
       "       [ 0.13751136, -0.06079593, -0.01042041, ..., -0.13931193,\n",
       "        -0.06634946, -0.21079655],\n",
       "       ...,\n",
       "       [-1.55493609, -0.26706107, -0.07488734, ...,  0.75063173,\n",
       "        -0.19631258, -0.18560636],\n",
       "       [-0.45982304, -0.18344231, -0.15851261, ...,  0.67326184,\n",
       "        -0.04185125, -0.20930762],\n",
       "       [-0.26071157, -0.09780911,  0.23047743, ...,  0.11369697,\n",
       "         0.12302336, -0.04066788]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection \n",
    "* train L1 regularizaed regession model to select features\n",
    "* train RF and select features based on feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression train score:  0.5373065621338003\n",
      "Linear Regression test score:  0.30975393764797143\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_pred = lin_reg.predict(X_val)\n",
    "\n",
    "print('Linear Regression train score: ', lin_reg.score(X_train, y_train))\n",
    "print('Linear Regression test score: ', lin_reg.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression train score:  0.8603672530310722\n",
      "Polynomial Regression test score:  -9.28696107443508\n"
     ]
    }
   ],
   "source": [
    "# polynomial regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "poly_reg = Pipeline([\n",
    "        (\"poly_features\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "        (\"lin_reg\", LinearRegression()),\n",
    "    ])\n",
    "poly_reg.fit(X_train, y_train)\n",
    "y_pred = poly_reg.predict(X_val)\n",
    "\n",
    "print('Polynomial Regression train score: ', poly_reg.score(X_train, y_train))\n",
    "print('Polynomial Regression test score: ', poly_reg.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression train score:  0.9787837790791976\n",
      "Random Forest Regression test score:  0.8638257843566127\n"
     ]
    }
   ],
   "source": [
    "# random forest regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "forest_reg.fit(X_train, y_train)\n",
    "y_pred = forest_reg.predict(X_val)\n",
    "\n",
    "print('Random Forest Regression train score: ', forest_reg.score(X_train, y_train))\n",
    "print('Random Forest Regression test score: ', forest_reg.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Regression train score:  0.9720230738193522\n",
      "XGBoost Regression test score:  0.8768605975271511\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.2,\n",
    "                max_depth = 4, alpha = 3, n_estimators = 100)\n",
    "xg_reg.fit(X_train,y_train)\n",
    "y_pred = xg_reg.predict(X_val)\n",
    "\n",
    "print('XGBoost Regression train score: ', xg_reg.score(X_train, y_train))\n",
    "print('XGBoost Regression test score: ', xg_reg.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 9.91208189\n",
      "Iteration 2, loss = 8.04189867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 6.43834047\n",
      "Iteration 4, loss = 4.82230652\n",
      "Iteration 5, loss = 3.21178204\n",
      "Iteration 6, loss = 1.90883469\n",
      "Iteration 7, loss = 1.16006012\n",
      "Iteration 8, loss = 0.94647237\n",
      "Iteration 9, loss = 0.83778368\n",
      "Iteration 10, loss = 0.69315228\n",
      "Iteration 11, loss = 0.61407167\n",
      "Iteration 12, loss = 0.52501517\n",
      "Iteration 13, loss = 0.45433434\n",
      "Iteration 14, loss = 0.41205426\n",
      "Iteration 15, loss = 0.39229104\n",
      "Iteration 16, loss = 0.37547405\n",
      "Iteration 17, loss = 0.36050975\n",
      "Iteration 18, loss = 0.34508750\n",
      "Iteration 19, loss = 0.33528100\n",
      "Iteration 20, loss = 0.32488736\n",
      "Iteration 21, loss = 0.31964353\n",
      "Iteration 22, loss = 0.30986911\n",
      "Iteration 23, loss = 0.30159637\n",
      "Iteration 24, loss = 0.29589775\n",
      "Iteration 25, loss = 0.28774813\n",
      "Iteration 26, loss = 0.28253546\n",
      "Iteration 27, loss = 0.27385405\n",
      "Iteration 28, loss = 0.27240341\n",
      "Iteration 29, loss = 0.26376806\n",
      "Iteration 30, loss = 0.25907340\n",
      "Iteration 31, loss = 0.25368502\n",
      "Iteration 32, loss = 0.24878771\n",
      "Iteration 33, loss = 0.24302884\n",
      "Iteration 34, loss = 0.24108495\n",
      "Iteration 35, loss = 0.23303622\n",
      "Iteration 36, loss = 0.23581847\n",
      "Iteration 37, loss = 0.22629387\n",
      "Iteration 38, loss = 0.22853639\n",
      "Iteration 39, loss = 0.21893128\n",
      "Iteration 40, loss = 0.21696984\n",
      "Iteration 41, loss = 0.21201405\n",
      "Iteration 42, loss = 0.20727828\n",
      "Iteration 43, loss = 0.20399149\n",
      "Iteration 44, loss = 0.19965475\n",
      "Iteration 45, loss = 0.19624458\n",
      "Iteration 46, loss = 0.19376618\n",
      "Iteration 47, loss = 0.19052183\n",
      "Iteration 48, loss = 0.18903776\n",
      "Iteration 49, loss = 0.18724250\n",
      "Iteration 50, loss = 0.18391633\n",
      "Iteration 51, loss = 0.18293880\n",
      "Iteration 52, loss = 0.17996215\n",
      "Iteration 53, loss = 0.17714287\n",
      "Iteration 54, loss = 0.17644885\n",
      "Iteration 55, loss = 0.17467256\n",
      "Iteration 56, loss = 0.17337179\n",
      "Iteration 57, loss = 0.17107684\n",
      "Iteration 58, loss = 0.17026847\n",
      "Iteration 59, loss = 0.16967856\n",
      "Iteration 60, loss = 0.17195570\n",
      "Iteration 61, loss = 0.17087868\n",
      "Iteration 62, loss = 0.16405839\n",
      "Iteration 63, loss = 0.16150351\n",
      "Iteration 64, loss = 0.16128859\n",
      "Iteration 65, loss = 0.16232844\n",
      "Iteration 66, loss = 0.16184449\n",
      "Iteration 67, loss = 0.16593503\n",
      "Iteration 68, loss = 0.15977578\n",
      "Iteration 69, loss = 0.15847811\n",
      "Iteration 70, loss = 0.15689362\n",
      "Iteration 71, loss = 0.15443588\n",
      "Iteration 72, loss = 0.15384209\n",
      "Iteration 73, loss = 0.15609949\n",
      "Iteration 74, loss = 0.15542989\n",
      "Iteration 75, loss = 0.15396755\n",
      "Iteration 76, loss = 0.15409451\n",
      "Iteration 77, loss = 0.15000007\n",
      "Iteration 78, loss = 0.15023709\n",
      "Iteration 79, loss = 0.15052357\n",
      "Iteration 80, loss = 0.14845246\n",
      "Iteration 81, loss = 0.15442857\n",
      "Iteration 82, loss = 0.14748195\n",
      "Iteration 83, loss = 0.14903018\n",
      "Iteration 84, loss = 0.15062351\n",
      "Iteration 85, loss = 0.14984749\n",
      "Iteration 86, loss = 0.14911048\n",
      "Iteration 87, loss = 0.14600444\n",
      "Iteration 88, loss = 0.14507202\n",
      "Iteration 89, loss = 0.14556752\n",
      "Iteration 90, loss = 0.14132395\n",
      "Iteration 91, loss = 0.14643182\n",
      "Iteration 92, loss = 0.15103085\n",
      "Iteration 93, loss = 0.14369265\n",
      "Iteration 94, loss = 0.13879181\n",
      "Iteration 95, loss = 0.13934637\n",
      "Iteration 96, loss = 0.13975898\n",
      "Iteration 97, loss = 0.13752851\n",
      "Iteration 98, loss = 0.14155482\n",
      "Iteration 99, loss = 0.13997633\n",
      "Iteration 100, loss = 0.13594009\n",
      "MLP Regression train score:  0.9212384113800252\n",
      "MLP Regression test score:  0.8465902224606217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# mlp\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mlp_reg = MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=100, alpha=0.001,\n",
    "                        solver='adam', verbose=10, random_state=42, tol=0.000000001)\n",
    "mlp_reg.fit(X_train, y_train)\n",
    "y_pred = mlp_reg.predict(X_val)\n",
    "\n",
    "print('MLP Regression train score: ', mlp_reg.score(X_train, y_train))\n",
    "print('MLP Regression test score: ', mlp_reg.score(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 24 is smaller than n_iter=100. Running 24 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "96 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "39 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/michal/.local/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/michal/.local/lib/python3.11/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/michal/.local/lib/python3.11/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/michal/.local/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "57 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/michal/.local/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/michal/.local/lib/python3.11/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/michal/.local/lib/python3.11/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/michal/.local/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/michal/.local/lib/python3.11/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.81004049 0.85482533 0.85440472        nan        nan 0.85512926\n",
      " 0.80306946        nan 0.84682978 0.85907517 0.82366047 0.83822129\n",
      "        nan 0.85646102 0.77461116        nan 0.84226693 0.85459432\n",
      " 0.8568202         nan 0.82813018        nan 0.82366047        nan\n",
      " 0.80855647 0.85826437 0.8540268  0.81004049 0.85440472 0.85817927\n",
      "        nan        nan 0.84460741        nan 0.85841651        nan\n",
      "        nan 0.84580565        nan 0.85436615        nan        nan\n",
      " 0.85826437 0.82823022 0.84996166 0.77917164        nan 0.8580184\n",
      " 0.83822129 0.84682978 0.8568202         nan 0.85459432        nan\n",
      " 0.8232569         nan        nan 0.84160929        nan 0.80306946\n",
      " 0.85470609 0.85470609 0.84460741 0.85817927 0.77422898 0.84160929\n",
      " 0.77461116 0.80320261 0.85907517 0.82928541        nan 0.83885479\n",
      "        nan 0.80911326 0.84580565 0.85482533 0.85294249        nan\n",
      " 0.85005729        nan        nan        nan 0.84226693 0.8536925\n",
      " 0.82231531 0.84996166 0.83885479        nan 0.82813018 0.80855647\n",
      " 0.83984621 0.80355037 0.80911326 0.77422898        nan 0.85436615\n",
      "        nan 0.85005729 0.77961438        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Regression train score:  0.9457812403215436\n",
      "MLP Regression test score:  0.8116780080558501\n",
      "XGBoost Regression train score:  0.9944849568806696\n",
      "XGBoost Regression test score:  0.8613572269827126\n",
      "Random Forest Regression train score:  0.9618481967227533\n",
      "Random Forest Regression test score:  0.869605087526908\n"
     ]
    }
   ],
   "source": [
    "# random search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(50, 50), (100, 100), (100, 100, 100), (100, 100, 100, 100)],\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [80, 100, 200],\n",
    "    'learning_rate': [0.1, 0.3, 0.5],\n",
    "    'max_depth': [3, 5, 6, 9],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "param_grid_forest = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# do search\n",
    "mlp_reg = MLPRegressor(max_iter=200, random_state=42, tol=0.000000001)\n",
    "xgb_reg = xgb.XGBRegressor(objective ='reg:squarederror', random_state=42)\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "\n",
    "mlp_search = RandomizedSearchCV(mlp_reg, param_grid_mlp, n_iter=100, cv=3, verbose=0, n_jobs=-1)\n",
    "xgb_search = RandomizedSearchCV(xgb_reg, param_grid_xgb, n_iter=100, cv=3, verbose=0, n_jobs=-1)\n",
    "forest_search = RandomizedSearchCV(forest_reg, param_grid_forest, n_iter=100, cv=3, verbose=0, n_jobs=-1)\n",
    "\n",
    "mlp_search.fit(X_train, y_train)\n",
    "xgb_search.fit(X_train, y_train)\n",
    "forest_search.fit(X_train, y_train)\n",
    "\n",
    "# get best of these three\n",
    "mlp_best = mlp_search.best_estimator_\n",
    "xgb_best = xgb_search.best_estimator_\n",
    "forest_best = forest_search.best_estimator_\n",
    "\n",
    "# compare best of these three\n",
    "print('MLP Regression train score: ', mlp_best.score(X_train, y_train))\n",
    "print('MLP Regression test score: ', mlp_best.score(X_val, y_val))\n",
    "print('XGBoost Regression train score: ', xgb_best.score(X_train, y_train))\n",
    "print('XGBoost Regression test score: ', xgb_best.score(X_val, y_val))\n",
    "print('Random Forest Regression train score: ', forest_best.score(X_train, y_train))\n",
    "print('Random Forest Regression test score: ', forest_best.score(X_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select best model\n",
    "# TODO: argue why this one is the best\n",
    "best_model = forest_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score:  0.8296569459512504\n",
      "Test RMSE:  0.8591884244971202\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "print('Test score: ', best_model.score(X_test, y_test))\n",
    "print('Test RMSE: ', np.sqrt(mean_squared_error(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on forest type classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "* Select the best interpretatable model, look at the coefficients and try to interpret them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
